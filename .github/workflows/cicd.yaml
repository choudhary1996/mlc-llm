name: MLC-LLM-CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install linters
        run: |
          pip install black isort pylint mypy
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install transformers fastapi uvicorn

      - name: Black
        run: black --diff --check ./python/ ./tests/python ./examples/python
        continue-on-error: true

      - name: isort
        run: isort --check-only --profile black ./python/ ./tests/python/ ./examples/python
        continue-on-error: true

      - name: pylint
        run: |
          export PYTHONPATH="./python:${PYTHONPATH}"
          pylint --exit-zero ./python/ || true
        continue-on-error: true

  build-linux:
    name: Build Linux x64
    runs-on: ubuntu-22.04
    outputs:
      build_status: ${{ steps.build.outcome }}
    steps:
      - name: Free disk space
        run: |
          echo "Before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          echo "After cleanup:"
          df -h

      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: 'recursive'
          fetch-depth: 0


      - name: Set up Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: mlc-chat-venv
          python-version: '3.10'
          channels: conda-forge

      - name: Install build dependencies
        shell: bash -el {0}
        run: |
          conda install -y -c conda-forge "cmake>=3.24" rust git ninja
          echo "Verify dependencies"
          cmake --version
          rustc --version
          git --version

      - name: Install Vulkan SDK
        run: |
          wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo tee /etc/apt/trusted.gpg.d/lunarg.asc
          sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan-jammy.list https://packages.lunarg.com/vulkan/lunarg-vulkan-jammy.list
          sudo apt-get update
          sudo apt-get install -y vulkan-sdk

      - name: Set up ccache
        uses: hendrikmuhs/ccache-action@v1.2
        with:
          key: linux-build
          max-size: 2G


      - name: Create build directory
        shell: bash -el {0}
        run: mkdir -p build

      - name: Generate config
        shell: bash -el {0}
        run: |
          cd build
          cat > config.cmake << 'EOF'
          set(TVM_SOURCE_DIR 3rdparty/tvm)
          set(CMAKE_BUILD_TYPE RelWithDebInfo)
          set(USE_VULKAN ON)
          set(USE_CUDA OFF)
          set(USE_METAL OFF)
          set(USE_OPENCL OFF)
          EOF
          cat config.cmake

      - name: Build libraries
        id: build
        shell: bash -el {0}
        run: |
          export PATH="/usr/lib/ccache:$PATH"
          cd build
          cmake .. -G Ninja
          ninja -j $(nproc)
          cd ..
          echo "=== Built libraries ==="
          find ./build -name "*.so" | head -20
        timeout-minutes: 60

      - name: Install package
        shell: bash -el {0}
        run: |
          cd python
          pip install -e .
          cd ..

      - name: Install TVM runtime
        shell: bash -el {0}
        run: |
          pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu

      - name: Install runtime dependencies
        shell: bash -el {0}
        run: |
          pip install datasets fastapi ml_dtypes openai pandas prompt_toolkit \
            requests safetensors sentencepiece shortuuid tiktoken tqdm transformers uvicorn
          pip install torch --index-url https://download.pytorch.org/whl/cpu


      - name: Validate
        shell: bash -el {0}
        run: |
          echo "Validate installation"
          echo "1. Check libraries: ls -l ./build/"
          find ./build -name "*.so" | xargs ls -l 2>/dev/null | head -10
          
          echo ""
          echo "2. CLI test: mlc_llm chat -h"
          mlc_llm chat -h
          
          echo ""
          echo "3. Import test: python -c 'import mlc_llm; print(mlc_llm)'"
          python -c "import mlc_llm; print(mlc_llm)"
          
          echo "=== Validation passed ==="

      - name: Build wheel
        shell: bash -el {0}
        run: |
          pip install build wheel
          cd python && pip wheel --no-deps -w ../wheels . && cd ..
          ls -la wheels/

      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: wheel-linux-x64
          path: wheels/*.whl
          retention-days: 30


  build-windows:
    name: Build Windows x64
    runs-on: windows-latest
    outputs:
      build_status: ${{ steps.build.outcome }}
    defaults:
      run:
        shell: cmd /C call {0}
    steps:
      - name: Git config
        run: git config --system core.longpaths true

      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: 'recursive'
          fetch-depth: 0

      - name: Set up Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: mlc-chat-venv
          channel-priority: strict
          environment-file: ci/build-environment.yaml
          auto-activate-base: false

      - name: Install dependencies
        shell: bash -el {0}
        run: |
          conda install -y -c conda-forge ninja
          cmake --version
          python --version

      - name: Setup MSVC
        uses: ilammy/msvc-dev-cmd@v1
        with:
          arch: x64

      - name: Install Vulkan SDK
        shell: pwsh
        run: |
          $vulkanVersion = "1.3.290.0"
          $installerUrl = "https://sdk.lunarg.com/sdk/download/$vulkanVersion/windows/VulkanSDK-$vulkanVersion-Installer.exe"
          $installerPath = "$env:TEMP\VulkanSDK-Installer.exe"
          
          Write-Host "Downloading Vulkan SDK $vulkanVersion..."
          Invoke-WebRequest -Uri $installerUrl -OutFile $installerPath
          
          Write-Host "Installing Vulkan SDK..."
          Start-Process -FilePath $installerPath -ArgumentList "--accept-licenses --default-answer --confirm-command install" -Wait -NoNewWindow
          
          # Set environment variable for this job
          $vulkanPath = "C:\VulkanSDK\$vulkanVersion"
          echo "VULKAN_SDK=$vulkanPath" >> $env:GITHUB_ENV
          echo "$vulkanPath\Bin" >> $env:GITHUB_PATH

      - name: Configure and build
        id: build
        shell: cmd
        run: |
          mkdir build
          cd build
          echo set(TVM_SOURCE_DIR 3rdparty/tvm) > config.cmake
          echo set(CMAKE_BUILD_TYPE RelWithDebInfo) >> config.cmake
          echo set(USE_VULKAN ON) >> config.cmake
          cmake .. -G "Visual Studio 17 2022" -A x64 -DVULKAN_SDK=%VULKAN_SDK%
          cmake --build . --config RelWithDebInfo --parallel
        timeout-minutes: 120

      - name: Copy built libraries
        shell: pwsh
        run: |
          # VS generator puts outputs in config-named subdirectory
          # Copy all DLLs and libs to build/ root for Python to find
          Get-ChildItem -Path build/RelWithDebInfo -Filter "*.dll" | Copy-Item -Destination build/ -Force
          Get-ChildItem -Path build/RelWithDebInfo -Filter "*.lib" | Copy-Item -Destination build/ -Force
          # Also check tvm subdirectory
          if (Test-Path build/tvm/RelWithDebInfo) {
            Get-ChildItem -Path build/tvm/RelWithDebInfo -Filter "*.dll" | Copy-Item -Destination build/ -Force
          }
          # List what we have
          Write-Host "Built libraries in build/:"
          Get-ChildItem -Path build -Filter "*.dll"

      - name: Install TVM runtime
        shell: bash -el {0}
        run: |
          pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu

      - name: Install package
        shell: bash -el {0}
        run: |
          pip install datasets fastapi ml_dtypes openai pandas prompt_toolkit requests safetensors sentencepiece shortuuid tiktoken tqdm transformers uvicorn
          pip install torch --extra-index-url https://download.pytorch.org/whl/cpu
          cd python
          pip install -e . --no-deps
          cd ..

      - name: Validate
        shell: bash -el {0}
        run: |
          mlc_llm chat -h
          python -c "import mlc_llm; print(mlc_llm)"

      - name: Build wheel
        shell: bash -el {0}
        run: |
          pip install build wheel
          cd python
          pip wheel --no-deps -w ../wheels .
          cd ..

      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: wheel-windows-x64
          path: wheels/*.whl
          retention-days: 30


  test-linux:
    name: Test Linux
    runs-on: ubuntu-22.04
    needs: build-linux
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Download wheel
        uses: actions/download-artifact@v4
        with:
          name: wheel-linux-x64
          path: wheels

      - name: Install wheel and dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y libvulkan1
          pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu || true
          pip install wheels/*.whl --force-reinstall
          pip install pytest datasets transformers fastapi uvicorn
          pip install torch --extra-index-url https://download.pytorch.org/whl/cpu

      - name: Validate installation
        run: |
          echo "=== Validation tests (per doc Step 4) ==="
          mlc_llm chat -h
          python -c "import mlc_llm; print(mlc_llm)"

      - name: Run unit tests
        run: |
          python -m pytest -v tests/python/ -m unittest \
            --ignore=tests/python/integration/ \
            --ignore=tests/python/op/ \
            --tb=short -x

  test-windows:
    name: Test Windows
    runs-on: windows-latest
    needs: build-windows
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-activate-base: false
          environment-file: ci/build-environment.yaml
          activate-environment: mlc-chat-venv

      - name: Install zstd (required by TVM/tvm.dll on Windows)
        shell: bash -el {0}
        run: conda install -y -c conda-forge zstd

      - name: Download wheel
        uses: actions/download-artifact@v4
        with:
          name: wheel-windows-x64
          path: wheels

      - name: Install and validate
        shell: bash -el {0}
        run: |
          pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu
          pip install pytest datasets fastapi ml_dtypes openai pandas prompt_toolkit requests safetensors sentencepiece shortuuid tiktoken tqdm transformers uvicorn
          pip install torch --extra-index-url https://download.pytorch.org/whl/cpu
          pip install wheels/*.whl --force-reinstall --no-deps
          python -m mlc_llm chat -h
          python -c "import mlc_llm; print(mlc_llm)"


  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [lint, build-linux, build-windows, test-linux, test-windows]
    if: always()
    outputs:
      success: ${{ steps.check.outputs.success }}
    steps:
      - name: Check results
        id: check
        run: |
          echo "Build Linux: ${{ needs.build-linux.result }}"
          echo "Build Windows: ${{ needs.build-windows.result }}"
          echo "Test Linux: ${{ needs.test-linux.result }}"
          echo "Test Windows: ${{ needs.test-windows.result }}"
          
          # Builds must succeed
          if [[ "${{ needs.build-linux.result }}" != "success" ]] || \
             [[ "${{ needs.build-windows.result }}" != "success" ]]; then
            echo "::error::Build failed"
            echo "success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Tests must succeed (gates release)
          if [[ "${{ needs.test-linux.result }}" != "success" ]] || \
             [[ "${{ needs.test-windows.result }}" != "success" ]]; then
            echo "::error::Tests failed - blocking release"
            echo "success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "success=true" >> $GITHUB_OUTPUT
          echo "MLC-LLM CI passed - ready for release"
